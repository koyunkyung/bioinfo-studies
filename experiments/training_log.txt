(num_epochs=100, batch_size=32, lr=1e-4, patience=10)를 가지고 모델 학습 진행함

### cell line embedding: bioBERT, drug embedding: morganFP ###




### cell line embedding: bioBERT, drug embedding: ECFP ###

    Epoch 1, Loss: 0.962758249358127
    Epoch 2, Loss: 0.8225368865226445
    Epoch 3, Loss: 0.5915853898776205
    Epoch 4, Loss: 0.4078317504180105
    Epoch 5, Loss: 0.30433866577713115
    Epoch 6, Loss: 0.27187010214516993
    Epoch 7, Loss: 0.23496128520683238
    Epoch 8, Loss: 0.22977360141904732
    Epoch 9, Loss: 0.2089535719469974
    ...
    Epoch 92, Loss: 0.08117529347931084
    Epoch 93, Loss: 0.07648492447639767
    Epoch 94, Loss: 0.07503570116272099
    Epoch 95, Loss: 0.07704144211387948
    Epoch 96, Loss: 0.07643403558942832
    Epoch 97, Loss: 0.07454689415661912
    Epoch 98, Loss: 0.07397390299133565
    Epoch 99, Loss: 0.0977239432303529
    Epoch 100, Loss: 0.08105322096104685


### cell line embedding: bioBERT, drug embedding: GNN embeddings ###




### cell line embedding: bioBERT, drug embedding: SELFIES ###


### cell line embedding: bioBERT, drug embedding: SAFE ###